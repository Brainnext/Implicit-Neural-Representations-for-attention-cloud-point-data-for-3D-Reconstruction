{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ5Lx7C2RW5sV6gnBl0UCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brainnext/Implicit-Neural-Representations-for-attention-cloud-point-data-for-3D-Reconstruction/blob/main/Implicit_Neural_Representations_for_attention_cloud_point_data_for_3D_Reconstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Installing and importing dependencies"
      ],
      "metadata": {
        "id": "QIPemetY-2dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install trimesh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRt6o9wd-lCH",
        "outputId": "01c032b8-df6d-4dc3-d29f-55ef9f6fe740"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trimesh\n",
            "  Downloading trimesh-4.9.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.12/dist-packages (from trimesh) (2.0.2)\n",
            "Downloading trimesh-4.9.0-py3-none-any.whl (736 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/736.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m727.0/736.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m736.5/736.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trimesh\n",
            "Successfully installed trimesh-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHeJu0PxwO1l",
        "outputId": "94024a30-581a-4ce6-c007-2a5ac6ffaf92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3sSXPKXv9lzv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import trimesh\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.nn import PointNetConv\n",
        "from torch_geometric.nn.pool import fps\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.data import Data # Needed for PyG operations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: The Implicit Function Decoder (INR) Design"
      ],
      "metadata": {
        "id": "nBtZKTuC_ATr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "L = 10 # Frequency count for positional encoding\n",
        "Z_DIM = 512 # Dimension of the latent shape code (z\n",
        "HIDDEN_DIM = 256 # Width of tHE MLP layers\n",
        "NUM_LAYERS = 8 # Depth of the MLP\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "  \"\"\"\n",
        "  Class for the postional encoding module\n",
        "  \"\"\"\n",
        "  def __init__(self, L=10):\n",
        "    super().__init__()\n",
        "    # 3D points * 2(sin/cos) * L frequencies\n",
        "    self.output_dim = 3 * 2 * L\n",
        "    self.L = L\n",
        "\n",
        "  def forward(self, X):\n",
        "    embeds = []\n",
        "    for i in range(self.L):\n",
        "      freq_band = 2.**i *np.pi\n",
        "      embeds.append(torch.sin(freq_band * x))\n",
        "      embeds.append(torch.cos(freq_band * x))\n",
        "    return torch.cat(embeds, dim=-1)"
      ],
      "metadata": {
        "id": "A8ZuElGC-1Uq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SDFDecoder(nn.Module):\n",
        "    def __init__(self, z_dim=Z_DIM, hidden_dim=HIDDEN_DIM, num_layers=NUM_LAYERS, L=L):\n",
        "        super().__init__()\n",
        "\n",
        "        self.positional_encoder = PositionalEncoding(L=L)\n",
        "        pos_dim = self.positional_encoder.output_dim\n",
        "\n",
        "        # Initial layer takes Positional Encoded point + Latent Code\n",
        "        self.in_dim = pos_dim + z_dim\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        # 1. First layer\n",
        "        layers.append(nn.Linear(self.in_dim, hidden_dim))\n",
        "        layers.append(nn.Softplus(beta=100)) # High beta Softplus is preferred for SDF\n",
        "\n",
        "        # 2. Main layers (Deep Network)\n",
        "        for i in range(num_layers - 2):\n",
        "            # Complex Note: We often concatenate the latent code 'z' again at intermediate layers\n",
        "            # (a \"skip connection\" of the conditioning vector) to aid optimization.\n",
        "            if i == (num_layers // 2) - 1: # Example: Concatenate z halfway\n",
        "                 layers.append(nn.Linear(hidden_dim + z_dim, hidden_dim))\n",
        "            else:\n",
        "                 layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "\n",
        "            layers.append(nn.Softplus(beta=100))\n",
        "\n",
        "        # 3. Output layer\n",
        "        layers.append(nn.Linear(hidden_dim, 1)) # Output is the single SDF value\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.z_dim = z_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, p, z):\n",
        "        # p: (B, N_query, 3), z: (B, Z_DIM)\n",
        "\n",
        "        # 1. Positional Encoding of points\n",
        "        p_enc = self.positional_encoder(p) # (B, N_query, pos_dim)\n",
        "\n",
        "        # 2. Replicate and Concatenate Latent Code (z)\n",
        "        # z must be expanded to match the number of query points (N_query)\n",
        "        z_expanded = z.unsqueeze(1).repeat(1, p.shape[1], 1) # (B, N_query, Z_DIM)\n",
        "\n",
        "        x = torch.cat([p_enc, z_expanded], dim=-1) # (B, N_query, pos_dim + Z_DIM)\n",
        "\n",
        "        # Iterate through the network\n",
        "        for i, layer in enumerate(self.net):\n",
        "            if isinstance(layer, nn.Linear) and i > 0:\n",
        "                # Re-concatenate latent code at the skip connection (e.g., halfway)\n",
        "                if i == self.net[i].in_features - 1: # Crude way to find the skip layer\n",
        "                    x = torch.cat([x, z_expanded], dim=-1)\n",
        "\n",
        "            x = layer(x)\n",
        "\n",
        "        # Final output is the predicted SDF (B, N_query, 1)\n",
        "        return x.squeeze(-1)"
      ],
      "metadata": {
        "id": "fqMGnQTduFXq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eikonal_loss(sdf_decoder, p_queries, z_codes):\n",
        "    \"\"\"\n",
        "    Calculates the Eikonal Loss: ||∇F(p)||_2 - 1)^2\n",
        "    This forces the gradient of the SDF to have unit magnitude (1).\n",
        "    \"\"\"\n",
        "\n",
        "    # CRITICAL: We need gradients w.r.t. the input points 'p_queries'\n",
        "    p_queries.requires_grad_(True)\n",
        "\n",
        "    # 1. Forward pass to get SDF values\n",
        "    # The output is (B * N_query)\n",
        "    sdf_output = sdf_decoder(p_queries, z_codes)\n",
        "\n",
        "    # Flatten the SDF output for gradient calculation\n",
        "    sdf_output_flat = sdf_output.view(-1)\n",
        "\n",
        "    # Create dummy tensor of ones for Jacobian (gradient) calculation\n",
        "    ones = torch.ones_like(sdf_output_flat)\n",
        "\n",
        "    # 2. Compute the gradient (∇F) using automatic differentiation\n",
        "    # gradients will be shape (B * N_query, 3)\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=sdf_output_flat,\n",
        "        inputs=p_queries,\n",
        "        grad_outputs=ones,\n",
        "        create_graph=True,  # IMPORTANT: Needed to allow backprop through this loss term\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "\n",
        "    # 3. Calculate the L2 norm (magnitude) of the gradient\n",
        "    # The norm is calculated across the last dimension (x, y, z)\n",
        "    gradient_norm = gradients.norm(2, dim=-1)\n",
        "\n",
        "    # 4. Compute the Eikonal loss: (||∇F|| - 1)^2\n",
        "    eikonal_loss_val = torch.mean((gradient_norm - 1)**2)\n",
        "\n",
        "    return eikonal_loss_val"
      ],
      "metadata": {
        "id": "yl6ZyK3VvYUd"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}